Complete Scheduling Workflow: From JSON to Output Generation

  Here's exactly how the scheduling system works from creation to
  execution and output generation:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                           SCHEDULING WORKFLOW
                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ğŸ“‹ STEP 1: JOB CREATION WITH SCHEDULE
     â”œâ”€ User creates job via web UI with JSON configuration
     â”œâ”€ Job data includes: { name, type, configuration, schedule }
     â””â”€ integrated_scheduler.py:94 â†’ create_job_with_schedule()

  ğŸ“‹ STEP 2: JOB STORAGE & SCHEDULING
     â”œâ”€ job_manager.py â†’ create_job() â†’ saves to SQL Server database
     â”œâ”€ integrated_scheduler.py:116 â†’ schedule_job() â†’ adds to
  APScheduler
     â””â”€ Creates trigger: CronTrigger/IntervalTrigger/DateTrigger

  ğŸ“‹ STEP 3: BACKGROUND SCHEDULING
     â”œâ”€ APScheduler runs in background thread
     â”œâ”€ When schedule triggers â†’ calls _execute_scheduled_job()
     â””â”€ integrated_scheduler.py:269 â†’ _execute_scheduled_job()

  ğŸ“‹ STEP 4: JOB EXECUTION ENGINE
     â”œâ”€ job_executor.py:57 â†’ execute_job()
     â”œâ”€ Loads job config from database
     â”œâ”€ Creates job instance: SqlJob or PowerShellJob
     â””â”€ Logs execution start to job_execution_history table

  ğŸ“‹ STEP 5: TYPE-SPECIFIC EXECUTION
     â”Œâ”€ SQL JOBS (sql_job.py):
     â”‚  â”œâ”€ Parses JSON: { sql: { query, connection_name, timeout } }
     â”‚  â”œâ”€ Gets database connection from connection pool  
     â”‚  â”œâ”€ Executes SQL query with pyodbc
     â”‚  â”œâ”€ Handles SELECT (returns rows) vs non-SELECT (rows 
  affected)
     â”‚  â””â”€ Formats output: "Query executed successfully. Returned X 
  rows."
     â”‚
     â””â”€ POWERSHELL JOBS (powershell_job.py):
        â”œâ”€ Parses JSON: { powershell: { script_content, parameters }
   }
        â”œâ”€ Creates temporary .ps1 file from script_content
        â”œâ”€ Executes via windows_utils.execute_powershell_script()
        â”œâ”€ Captures stdout/stderr from PowerShell process
        â””â”€ Returns formatted output with execution results

  ğŸ“‹ STEP 6: RESULT PROCESSING & LOGGING
     â”œâ”€ job_executor.py:125 â†’ _log_execution_completion()
     â”œâ”€ Updates job_execution_history with:
     â”‚  â”œâ”€ Status (SUCCESS/FAILED/TIMEOUT)
     â”‚  â”œâ”€ Duration in seconds
     â”‚  â”œâ”€ Output text (first 1000 chars for API)
     â”‚  â”œâ”€ Error messages (if any)
     â”‚  â””â”€ Full metadata as JSON
     â””â”€ Database stores complete execution history

  JSON Configuration Examples:

  SQL Job JSON:

  {
    "name": "Daily Sales Report",
    "job_type": "sql",
    "configuration": {
      "sql": {
        "query": "SELECT COUNT(*) as sales_count FROM orders WHERE 
  date = GETDATE()",
        "connection_name": "production_db",
        "query_timeout": 300,
        "max_rows": 1000
      },
      "basic": {
        "timeout": 600,
        "max_retries": 3
      }
    },
    "schedule": {
      "type": "cron",
      "cron": "0 0 8 * * 1-5"  // 8 AM weekdays
    }
  }

  PowerShell Job JSON:

  {
    "name": "System Cleanup",
    "job_type": "powershell",
    "configuration": {
      "powershell": {
        "script_content": "Get-ChildItem C:\\Temp -Recurse | 
  Remove-Item -Force",
        "execution_policy": "Bypass",
        "timeout": 300
      }
    },
    "schedule": {
      "type": "interval",
      "interval": {
        "hours": 24
      }
    }
  }

  Output Generation Process:

  SQL Jobs Output:

  1. SELECT Queries: Returns structured data with columns and rows
  2. Non-SELECT: Returns rows affected count
  3. Format: "Query executed successfully. Returned 45 rows."
  4. Metadata: Full result set stored in JSON metadata field

  PowerShell Jobs Output:

  1. Captures: stdout, stderr, exit code from PowerShell process
  2. Format: Raw PowerShell console output
  3. Success: Returns script output text
  4. Failure: Returns error messages and stack traces

  Database Storage:

  All results stored in job_execution_history table:
  - status: SUCCESS/FAILED/TIMEOUT
  - output: Text summary (truncated for API responses)
  - error_message: Error details if failed
  - metadata: Full JSON with complete results, timing, parameters
  - duration_seconds: Execution time
  - start_time/end_time: Timestamps

  The system provides complete audit trail of all scheduled job
  executions with full output capture and structured logging.